---
title: "TFM"
author: "Javier Ortiz"
date: "30 de Junio de 2017"
output: 
  word_document: null
  html_document: default
  number_sections: yes
  theme: cosmo
  highlight: default
---

******
## Carga de librerias
******
Load libraries
```{r librerias, include=FALSE}
if(! "ggplot2" %in% installed.packages()) install.packages("ggplot2",dependencies = TRUE)
library(ggplot2)
if(! "data.table" %in% installed.packages()) install.packages("data.table",dependencies = TRUE)
library(data.table)
if(! "caret" %in% installed.packages()) install.packages("caret",dependencies = TRUE)
library(caret)
if(! "kableExtra" %in% installed.packages()) install.packages("kableExtra",dependencies = TRUE)
library(kableExtra)
if(! "xtable" %in% installed.packages()) install.packages("xtable",dependencies = TRUE)
library(xtable)
if(! "corrplot" %in% installed.packages()) install.packages("corrplot",dependencies = TRUE)
library(corrplot)
if(! "lubridate" %in% installed.packages()) install.packages("lubridate",dependencies = TRUE)
library(lubridate)
if(! "caret" %in% installed.packages()) install.packages("caret",dependencies = TRUE)
library(caret)
if(! "lightGBM" %in% installed.packages()) install.packages("lightGBM",dependencies = TRUE)
library(lightGBM)
rm(list = ls());
gc();
```

******
## Carga de datos y análisis descriptivo de los datos
******

```{r descriptiva, echo=FALSE}
# Cargamos los datos datasets macro, train y test
directorio_trabajo <- setwd("C:/Users/Javier Ortiz/Desktop/Master Big Data/TFM/TFM-UEMC")
getwd()

macro <- fread(file="Estudio preliminar/Datos/macro.csv", header=TRUE, sep=",", na.strings="NA", stringsAsFactors=TRUE)

train <- fread(file="Estudio preliminar/Datos/train.csv", header=TRUE, sep=",", na.strings="NA", stringsAsFactors=TRUE)

test <- fread(file="Estudio preliminar/Datos/test.csv", header=TRUE, sep=",", na.strings="NA", stringsAsFactors=TRUE)

#Resumen del dataset train
dim(train)
rowSums(is.na(train))
names(train)
head(train)
tail(train)
summary(train)
str(train)

#Resumen del dataset test
dim(test)
rowSums(is.na(test))
names(test)
head(test)
tail(test)
summary(test)
str(test)

#Resumen del dataset macro
dim(macro)
rowSums(is.na(macro))
names(macro)
head(macro)
tail(macro)
summary(macro)
str(macro)

# Precios por año
boxplot(train$price_doc~year(train$timestamp),data=train, main="Precios x año", xlab="Año", ylab="Precio")

# Precios por año
plot(train$price_doc~train$sub_area, main="Precios x sub area", xlab="Año", ylab="Sub-area", col="red")


```

******
## Limpieza del dataset y selección de datos
******

```{r clean, echo=FALSE}
# Limpiamos las variables del dataset train que vamos a emplear
train$full_sq[is.na(train$full_sq)] <- 0
train$life_sq[is.na(train$life_sq)] <- 0
train$build_year[is.na(train$build_year)] <- 0
train$floor[is.na(train$floor)] <- 0
train$max_floor[is.na(train$max_floor)] <- 0
train$num_room[is.na(train$num_room)] <- 0
train$kitch_sq[is.na(train$kitch_sq)] <- 0
train$state[is.na(train$state)] <- 0
train$material[is.na(train$material)] <- 0

# Limpiamos las variables del dataset test que vamos a emplear
test$full_sq[is.na(test$full_sq)] <- 0
test$life_sq[is.na(test$life_sq)] <- 0
test$build_year[is.na(test$build_year)] <- 0
test$floor[is.na(test$floor)] <- 0
test$max_floor[is.na(test$max_floor)] <- 0
test$num_room[is.na(test$num_room)] <- 0
test$kitch_sq[is.na(test$kitch_sq)] <- 0
test$state[is.na(test$state)] <- 0
test$material[is.na(test$material)] <- 0

# Creamos la variable price_doc en el dataset de test
test$price_doc <- 0

# Limpiamos los nulos de los campos que vamos a utilizar del dataset macro
macro$deposits_value[is.na(macro$deposits_value)] <- 0
macro$deposits_growth[is.na(macro$deposits_growth)] <- 0
macro$deposits_rate[is.na(macro$deposits_rate)] <- 0
macro$mortgage_value[is.na(macro$mortgage_value)] <- 0
macro$mortgage_growth[is.na(macro$mortgage_growth)] <- 0
macro$mortgage_rate[is.na(macro$mortgage_rate)] <- 0
macro$income_per_cap[is.na(macro$income_per_cap)] <- 0
macro$real_dispos_income_per_cap_growth[is.na(macro$real_dispos_income_per_cap_growth)] <- 0
macro$salary[is.na(macro$salary)] <- 0
macro$salary_growth[is.na(macro$salary_growth)] <- 0
macro$fixed_basket[is.na(macro$fixed_basket)] <- 0
macro$unemployment[is.na(macro$unemployment)] <- 0
macro$employment[is.na(macro$employment)] <- 0
macro$invest_fixed_capital_per_cap[is.na(macro$invest_fixed_capital_per_cap)] <- 0
macro$invest_fixed_assets[is.na(macro$invest_fixed_assets)] <- 0

```

******
## Análisis exploratorio apoyado en algún método NO supervisado (Clustering)
******
Normalización de atributos
```{r exploratory,eval=TRUE, echo=FALSE}

#Elijo solo variables númericas para subconjunto de datos de train
train_sub <- subset(train,select = c(full_sq,life_sq,floor,max_floor,material,build_year,num_room,kitch_sq,state,price_doc))

# Creo el subconjunto de datos de macro con las variables que me parecen más relevantes
macro_sub <- subset(macro,select = c(deposits_value,deposits_growth,deposits_rate,mortgage_value,mortgage_growth,mortgage_rate,income_per_cap,real_dispos_income_per_cap_growth,salary,salary_growth,fixed_basket,unemployment,employment,invest_fixed_capital_per_cap,invest_fixed_assets))

#Gráficos mod3 u1 pág 115
plot(train_sub$price_doc,train$full_sq ,main = "Full-sq Price", pch=20)
ggplot(aes(x=price_doc), data=train) + 
    geom_density(fill='red', color='red') + 
    facet_grid(~product_type) + 
    scale_x_continuous(trans='log')

#Matriz de correlación mod3 u1 pág 115
matCor <- cor(train_sub[,c("full_sq","life_sq","floor","max_floor","material","build_year","num_room","kitch_sq","price_doc")])

corrplot(cor(train_sub, use="complete.obs"),method = "number",order ="alphabet")

# matCor[is.na(matCor)] <- 0
# 
# plot.new() 
# # Generamos una paleta de colores más claros 
# col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
# 
# # Dibujamos la matriz de coloración con cuadrados de colores y etiquetas negras 
# corrplot(matCor, method = "shade", shade.col = NA, tl.col = "black", tl.srt = 45, col = col(200), addCoef.col="black", order="AOE", mar = c(1,0,2,0),  main = "Fig 3.1. Predictors correlation matrix")

#Elijo solo varibles númericas
test_macro_mod <- subset(test_macro,select = c(full_sq,life_sq,floor,max_floor,material,build_year,num_room,kitch_sq,green_zone_part,indust_part))

# Creación de conjuto de datos uniendo por fecha entre train,test y macro
train_macro <- merge(train_sub,macro_sub,"timestamp")
test_macro <- merge(test_sub,macro_sub,"timestamp")

#Realizamos 15 iteraciones empleando y empleando el indicador withniss obtendremos la suma de los cuadrados de las distancias entre los centros determinados por el algoritmo kmeans y los puntos que están dentro de cada cluster.
kmeans(train_sub,centers=9)$tot.withinss
wss <- (nrow(train_sub)-1)*sum(apply(train_sub,2,var))
  for (i in 2:15) wss[i] <- sum(kmeans(train_sub,
                                       centers=i)$withinss)

#Dibujamos el gráfico para ver cual es el número de clústers más correctos para elegir
plot(1:15, wss, type="b", xlab="Numero de Clusters",
     ylab="Sumas de cuadrados dentro de los grupos",
     main="Num de clusters óptimos",
     pch=20, cex=2)

kmeans.result <- kmeans(train_sub, centers=5)
centros <- kmeans.result$centers[kmeans.result$cluster,]
distancias <- sqrt(rowSums((train_sub - centros)^2))
outliers <- order(distancias, decreasing=T)[1:5]
train_sub[outliers,]

#Detección de outliers
plot(train_sub[,c("full_sq","life_sq","floor","max_floor","material","build_year","num_room","kitch_sq","price_doc")], main="Detección de outliers", pch="o",
col=kmeans.result$cluster, cex=0.3)
points(kmeans.result$centers[,c("full_sq","life_sq","floor","max_floor","material","build_year","num_room","kitch_sq","price_doc")], col=1:5, pch=8, cex=1.5)
points(train_sub[outliers,c("full_sq","life_sq","floor","max_floor","material","build_year","num_room","kitch_sq","price_doc")], col=4, pch="+", cex=1.5)
points(matrix(colMeans(train_sub),nrow=1,ncol=2),cex=3,col=12,pch=19)

```

******
## Selección de variables, elección, construcción y optimización de al menos dos modelos machine Learning supervisados distintos (Prototype modelo (KNN))
******
```{r reg_lineal, echo=FALSE}
sapply(test_macro_mod,function(x) sum(is.na(x)))
sapply(test_macro_mod,function(x) length(unique(x)))
test_macro_mod$Class <- factor(ifelse(test_macro_mod$G3<10, "SUS", "APR"))

#Creamos la partición tanto para entrenamiento y para test 
train.sample <- createDataPartition(test_macro_mod$Class, p=0.8, list = F)
train.test_macro_mod <- test_macro_mod[train.sample,]
test.test_macro_mod <- test_macro_mod[ -train.sample,]

#Buscamos las variables que no aportan al clasificador.
zero.var.train.students_mod <- nearZeroVar(train.students_mod[, -dim(train.students_mod)[2]], saveMetrics = F)
colnames(train.students_mod)[zero.var.train.students_mod]

#Variables que tienen correlación.
cor.train.students_mod.matrix <- cor( train.students_mod[, -dim(train.students_mod)[2]] )
cor.train.students_mod.index <- findCorrelation(cor.train.students_mod.matrix, 0.80)

cor.train.students_mod <- train.students_mod[, -cor.train.students_mod.index]
cor.test.students_mod <- test.students_mod[, -cor.train.students_mod.index]

xTrans.students_mod <- preProcess(cor.train.students_mod[, -dim(cor.train.students_mod)[2]])
train.students_mod.prep <- predict( xTrans.students_mod, cor.train.students_mod[,-dim(cor.train.students_mod)[2]])
train.students_mod.prep$Class <- cor.train.students_mod$Class

test.students_mod.prep <- predict( xTrans.students_mod, cor.test.students_mod[,-dim(cor.test.students_mod)[2]])
test.students_mod.prep$Class <- cor.test.students_mod$Class

# Remuestreamos el conjunto de entreno
knn.control <- trainControl(method="repeatedcv", repeats = 5)

#Entrenamos el modelo
knn.students_mod.model <- train(x=train.students_mod.prep[,-dim(train.students_mod.prep)[2]], y=train.students_mod.prep$Class, method="knn", tuneLength = 10, trControl = knn.control)

#Mostramos el modelo resultante
knn.students_mod.model

#Mostramos mediante un gráfico la metrica Accuracy
knnplot <- plot(knn.students_mod.model, metric="Accuracy")
print(knnplot)

#
knn.students_mod.test <- predict(knn.students_mod.model, newdata = test.students_mod.prep[,-dim(train.students_mod.prep)[2]])

#Matriz de confusión.
confusionMatrix(knn.students_mod.test,test.students_mod.prep$Class)

#Se da valor si es aprobado o supendido (1,0)
pr <- prediction(ifelse(knn.students_mod.test == 'APR',1,0), ifelse(test.students_mod.prep$Class == 'APR',1,0))

#Mostramos el rendimiento del modelo mediante un gráfico
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
```

******
## Selección de variables, elección, construcción y optimización de al menos dos modelos machine Learning supervisados distintos (ROC-Based Classifier)
******
Realizamos las misma operaciones que para el primer modelo
```{r ROC, echo=FALSE}
roc.control <- trainControl(method="repeatedcv", repeats = 5)

roc.students_mod.model <- train(x=train.students_mod.prep[,-dim(train.students_mod.prep)[2]], y=train.students_mod.prep$Class, method="rocc", tuneLength = 10, trControl = roc.control)

roc.students_mod.model

rocplot <- plot(roc.students_mod.model, metric="Accuracy")
print(rocplot)

roc.students_mod.test <- predict(roc.students_mod.model, newdata = test.students_mod.prep[,-dim(train.students_mod.prep)[2]])

confusionMatrix(roc.students_mod.test,test.students_mod.prep$Class)

pr <- prediction(ifelse(roc.students_mod.test == 'APR' ,1,0), ifelse(test.students_mod.prep$Class == 'APR',1,0))

prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
```

******
## Evaluación y comparación de dichos modelos realizados
******
Gracias al paquete Caret podremos comparar los modelos.
```{r comparation, echo=FALSE}
models <- list(knn.students_mod.model, roc.students_mod.model)
compar.models <- resamples(models)
summary(compar.models)
```
******
## Gráficos
******
Mediante el gráfico podemos ver como el modelo 2 (ROC-Based Classifier) tiene una precisión mayor que el primer modelo.
```{r graphics, echo=FALSE}
dotplot(compar.models)
```